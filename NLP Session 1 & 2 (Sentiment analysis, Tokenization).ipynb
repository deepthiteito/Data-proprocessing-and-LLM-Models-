{"cells":[{"cell_type":"code","execution_count":null,"id":"8c5b750a-4c76-4222-8784-ea44f0a7a2a1","metadata":{"id":"8c5b750a-4c76-4222-8784-ea44f0a7a2a1"},"outputs":[],"source":["# Natural Language Processing or Text Mining - Text Data is Unsupervised Learning Data.\n","# Unsupervised Learning means no proper structure, no variables, and also traditional models\n","# do not work on this data\n","\n","# Text Data must be processed and convert to Supervised Learning where it will have proper\n","# structure, variable formation and traditional models will work.\n","\n","# Different types of text data in terms of documents(PDF, Word Docs, OCR Files(PDF Images),\n","# Web Pages, Social Media Posts/Updates/Text Content, Databases(XML Format), Text from Images,\n","# IPO Documents(Redherring Prospectus), etc.)"]},{"cell_type":"markdown","source":["Optical Character Recognition, or OCR, is a technology that allows you to convert different types of documents, such as scanned paper documents, PDF files, or images captured by a digital camera, into editable and searchable data."],"metadata":{"id":"dsG_PnDZThXg"},"id":"dsG_PnDZThXg"},{"cell_type":"code","execution_count":null,"id":"e1a9a051-72c4-417b-9d0f-e88d3a0b76fb","metadata":{"id":"e1a9a051-72c4-417b-9d0f-e88d3a0b76fb"},"outputs":[],"source":["# Web Scraping - Scraping text data from webpages. Web Pages are typically html pages\n","# that has many other factors along with text like headings, Page Details, Styling, fonts,\n","# etc.\n","\n","# Scrape Text content only. Libraries used are requests, bs4, nltk\n","# requests library for url webpage scraping\n","# bs4 for scraping text content"]},{"cell_type":"code","execution_count":null,"id":"f6e9a6ba-3319-4619-a233-54fd72dec299","metadata":{"id":"f6e9a6ba-3319-4619-a233-54fd72dec299"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"markdown","source":["BeautifulSoup is a popular Python library used for web scraping, i.e., extracting data from HTML and XML pages.\n","\n","What it does\n","\n","Parses messy or poorly formatted HTML.\n","\n","Lets you easily search, navigate, and extract parts of a webpage (like titles, tables, links, text, etc.).\n","\n","Makes web scraping much simpler than manually using regex or raw string methods.\n","\n","Why is it called BeautifulSoup?\n","\n","The name is inspired by:\n","\n","The idea of turning \"messy\" HTML into \"beautiful\" structured data that you can easily work with ‚Äî like turning a messy soup into something clear.\n","\n","A reference to the poem \"Beautiful Soup\" from Alice in Wonderland, where the Mock Turtle sings about soup.\n","The library‚Äôs creator liked the whimsical reference, and it fit the concept of dealing with a ‚Äúsoup‚Äù of markup.\n","\n","So the name is partly metaphorical (cleaning messy markup) and partly literary (Alice in Wonderland"],"metadata":{"id":"qO2fwsJKO-Tu"},"id":"qO2fwsJKO-Tu"},{"cell_type":"markdown","source":["‚úÖ 1. Requests Library\n","\n","Requests is a Python library used to send HTTP requests to websites.\n","\n","You use it to:\n","\n","Download a webpage\n","\n","Submit forms\n","\n","Call APIs\n","\n","Send GET/POST requests"],"metadata":{"id":"ylZK6VTjPbRK"},"id":"ylZK6VTjPbRK"},{"cell_type":"markdown","source":["BeautifulSoup is the actual class/library you use\n","\n","bs4 = the module/package\n","\n","BeautifulSoup = the class inside that package\n","BeautifulSoup (part of the bs4 package) is used to parse HTML or XML and extract data easily.\n","\n","It helps you:\n","\n","Find tags (<h1>, <p>, <a>)\n","\n","Extract text\n","\n","Extract attributes (like href)\n","\n","Navigate the DOM"],"metadata":{"id":"cK2bB5WNPktb"},"id":"cK2bB5WNPktb"},{"cell_type":"code","execution_count":null,"id":"799c07d5-9c06-4149-b807-1df588f4455d","metadata":{"id":"799c07d5-9c06-4149-b807-1df588f4455d"},"outputs":[],"source":["response = requests.get(\"https://www.britannica.com/science/climate-change/Climate-change-since-the-emergence-of-civilization\")\n","soup = BeautifulSoup(response.text, 'lxml') # Create a BeautifulSoup object from the webpage‚Äôs HTML using the fast lxml parser\n","\n","#1. BeautifulSoup(response.text, ...)\n","\n","#This creates a BeautifulSoup object from the HTML text you downloaded.\n","\n","#response.text = the HTML content you got from the website\n","\n","#BeautifulSoup(...) = parses that HTML and turns it into a structured object you can search\n","\n","#Example: find tags, extract text, get links, etc."]},{"cell_type":"markdown","source":["We need to send **HTTP requests to websites** because that is the *only official way* to ask a website to give us its data or page content.\n","\n","Here‚Äôs the simplest explanation:\n","\n","---\n","\n","# ‚úÖ Why do we send HTTP requests to websites?\n","\n","### **1. Websites store data on a server**\n","\n","A website‚Äôs content (HTML, images, text, etc.) is stored on a remote server.\n","\n","Your computer **cannot access that data directly**.\n","\n","### **2. HTTP is the ‚Äúlanguage‚Äù we use to communicate with the server**\n","\n","When you open any website in your browser, your browser secretly does this:\n","\n","```\n","GET /page\n","Host: example.com\n","```\n","\n","This is an **HTTP GET request**, asking:\n","\n","> ‚ÄúPlease send me this webpage.‚Äù\n","\n","### **3. The server responds with the webpage**\n","\n","The server replies with:\n","\n","* HTML\n","* CSS\n","* Images\n","* JSON data\n","* Anything the website contains\n","\n","Your browser displays it.\n","\n","---\n","\n","# ‚úÖ Why *we* (in Python) need to send HTTP requests?\n","\n","Because we want to:\n","\n","### ‚úîÔ∏è Download a webpage\n","\n","(using `requests.get()`)\n","\n","### ‚úîÔ∏è Scrape data from a webpage\n","\n","(using BeautifulSoup)\n","\n","### ‚úîÔ∏è Access an API (weather, maps, stock prices)\n","\n","(using GET/POST requests)\n","\n","### ‚úîÔ∏è Submit data\n","\n","(logging in, sending a form, uploading info)\n","\n","---\n","\n","# üîÑ Summary (super simple)\n","\n","* A website is stored on a server.\n","* To get anything from that server, we must **ask** using **HTTP requests**.\n","* Requests library helps Python do what your browser normally does.\n","\n","---\n","\n","If you want, I can show you:\n","\n","* How browsers send requests internally\n","* A diagram of how server‚Äìclient communication works\n","* A short analogy (like ordering food in a restaurant)\n"],"metadata":{"id":"HiuQs4wbQFAw"},"id":"HiuQs4wbQFAw"},{"cell_type":"code","execution_count":null,"id":"e2021025-866a-4f88-8ee6-57277def9ede","metadata":{"id":"e2021025-866a-4f88-8ee6-57277def9ede"},"outputs":[],"source":["paragraphs = soup.find_all('p')\n","paragraphs_txt=[p.text for p in paragraphs]\n","# soup.find_all() searches the HTML for all tags of a certain type.'p' means ‚Äúparagraph tags‚Äù\n","#This is a list comprehension.\n","#It loops over each <p> tag\n","# Extracts only its text (no HTML)\n","# Stores it in a clean Python list"]},{"cell_type":"code","execution_count":null,"id":"e18075de-44fd-45ea-9de3-f1a7ba8eab35","metadata":{"id":"e18075de-44fd-45ea-9de3-f1a7ba8eab35"},"outputs":[],"source":["# Text preprocessing - Cleaning up text using re library. re(Regular Expressions) library\n","# used for identifying different text patterns and clean them.\n","\n","# Text patterns like email, digits, words, spaces, word boundaries(start/end), etc are\n","# predefined and are used for cleaning text data.\n","\n","# Text preprocessing involves removing punctuations, special characters, digits, spaces,\n","# emoji's, hyperlinks, specific characters, etc."]},{"cell_type":"markdown","id":"00aeec73-bcdb-4447-a860-1f7ce5cfbf49","metadata":{"id":"00aeec73-bcdb-4447-a860-1f7ce5cfbf49"},"source":["![image.png](attachment:ed226b74-2beb-4118-9d91-67e4891c49e6.png)"]},{"cell_type":"code","execution_count":null,"id":"2f778631-26fe-4a1d-add0-36f21d9de4cc","metadata":{"id":"2f778631-26fe-4a1d-add0-36f21d9de4cc"},"outputs":[],"source":["import re\n","# The re library in Python is the built-in module for regular expressions.\n","#  Regular expressions are powerful patterns used for matching character combinations in strings."]},{"cell_type":"markdown","source":["That line of code, paragraphs_txt=re.sub(pattern,\"\",str(paragraphs_txt)), is performing text cleaning using regular expressions.\n","\n","Here's a breakdown:\n","\n","re.sub(): This is a function from Python's re (regular expression) library. It stands for \"substitute\" and is used to find all occurrences of a pattern in a string and replace them with a specified replacement string.\n","pattern:\n","So, the overall purpose of this line is to remove special characters, punctuation (excluding periods), and symbols from the text, leaving behind only letters, numbers, spaces, and periods, making the text cleaner for further analysis."],"metadata":{"id":"6-W8zTWodiVs"},"id":"6-W8zTWodiVs"},{"cell_type":"code","execution_count":null,"id":"ce93fef5-c57b-48ec-9465-784b87284e73","metadata":{"id":"ce93fef5-c57b-48ec-9465-784b87284e73"},"outputs":[],"source":["pattern=r'[^a-zA-Z0-9\\s.]' # ^ ‚Üí start of string"]},{"cell_type":"code","execution_count":null,"id":"417ff3f9-5b49-466b-ad25-511b246da2ad","metadata":{"id":"417ff3f9-5b49-466b-ad25-511b246da2ad"},"outputs":[],"source":["paragraphs_txt=re.sub(pattern,\"\",str(paragraphs_txt)) # replace pattern by substituting with space\n","\n","# rs.sub(\"pattern to be replace\", \"pattern replacement\", data)"]},{"cell_type":"code","execution_count":null,"id":"22594e34-6732-4556-80ac-b2a32cbc9054","metadata":{"id":"22594e34-6732-4556-80ac-b2a32cbc9054"},"outputs":[],"source":["paragraphs_txt=re.sub(r'[0-9]+',\"\",paragraphs_txt) # Remove All Digits/numbers"]},{"cell_type":"code","execution_count":null,"id":"0b39db54-0cac-441e-886e-4a855ba52b4a","metadata":{"id":"0b39db54-0cac-441e-886e-4a855ba52b4a"},"outputs":[],"source":["paragraphs_txt=paragraphs_txt.lower()\n","\n","# Convert text to Lower Case. All comparitive words are in lower case. predefined lists or\n","# lexicons are in smallcap/lower case. ind != Ind ; ind = ind\n","# lexicons simply mean collections of words, usually with their meanings or uses.\n","# Think of a lexicon as a specialized dictionary."]},{"cell_type":"code","execution_count":null,"id":"20f1bc20-5242-4a89-8a24-d53e7a73fee9","metadata":{"id":"20f1bc20-5242-4a89-8a24-d53e7a73fee9"},"outputs":[],"source":["# Tokenization - Break text into tokens/words or sentences.\n","# Sentence Tokenization - Breaking text into sentences. default delimiter is fullstop\n","# Word Tokenization - Breaking text into words or tokens. default delimiter is space"]},{"cell_type":"code","execution_count":null,"id":"d45e081e-b64b-4873-8dc2-95e0069975ee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d45e081e-b64b-4873-8dc2-95e0069975ee","executionInfo":{"status":"ok","timestamp":1763981491761,"user_tz":-330,"elapsed":67955,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"29d3ba67-30e2-4346-8d22-8ae28710bb3c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package english_wordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package extended_omw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n","[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mock_corpus.zip.\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pe08.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package tagsets_json to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets_json.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}],"source":["# !pip install nltk\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","nltk.download(\"all\")"]},{"cell_type":"code","execution_count":null,"id":"71a625d4-862a-41da-9e21-2c4452f1d7b6","metadata":{"id":"71a625d4-862a-41da-9e21-2c4452f1d7b6"},"outputs":[],"source":["climatesentences=sent_tokenize(paragraphs_txt) # SEntiment analysis"]},{"cell_type":"code","execution_count":null,"id":"4fc5b5e9-037e-48d9-9623-1913045115fc","metadata":{"id":"4fc5b5e9-037e-48d9-9623-1913045115fc"},"outputs":[],"source":["# On Sentences - Sentiment Analysis is done. positive, negative, neutral sentiments are\n","# generated for each sentence.\n","# Many Sentiment Analysis Models like VADER, Text Blob Polarity Model, Stanford Sentiment Model\n","# ,nltk sentiment , etc.\n","\n","# Most popular and highly accurate is Text Blob Library sentiment model. Text Blob Model\n","# provides 2 scores - Polarity Score and Subjectivity Score.\n","# Polarity Score is a value that lies between -1 to 1. Using this score sentiment classification is\n","# done\n","#his will include how values close to -1 indicate negative sentiment, values close to 1 indicate positive sentiment,\n","# and values around 0 indicate neutral sentiment.\n","# Subjectivity Score is a value that lies between 0 and 1. Close to 1 is high personal\n","# opinion (involves adverbs & Superlatives) and Close to 0 is low personal opinion."]},{"cell_type":"markdown","source":["VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It's often used for text from sources like Twitter, product reviews, and other informal texts.\n","\n","Here are some key characteristics of VADER:\n","\n","Lexicon-based: It uses a dictionary of words (lexicon) where each word is pre-scored for its sentiment (positive, negative, or neutral)."],"metadata":{"id":"ZtAD3jXCiFWQ"},"id":"ZtAD3jXCiFWQ"},{"cell_type":"code","execution_count":null,"id":"d2a4e58f-f8c2-472a-98ad-087ed54b7c1b","metadata":{"id":"d2a4e58f-f8c2-472a-98ad-087ed54b7c1b"},"outputs":[],"source":["# !pip install textblob\n","from textblob import TextBlob"]},{"cell_type":"markdown","source":["The TextBlob library is a user-friendly Python library designed for processing textual data, offering a simplified API for various Natural Language Processing (NLP) tasks. Its primary capabilities include sentiment analysis, which provides polarity (positive/negative) and subjectivity scores for text, as well as part-of-speech tagging, noun phrase extraction, tokenization, word inflection, and spelling correction, making it a versatile tool for quick text analysis and understanding."],"metadata":{"id":"yYm3xfi9enYA"},"id":"yYm3xfi9enYA"},{"cell_type":"code","execution_count":null,"id":"4ab4d788-f85b-4767-b2a1-e3846e788f13","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ab4d788-f85b-4767-b2a1-e3846e788f13","executionInfo":{"status":"ok","timestamp":1763981492063,"user_tz":-330,"elapsed":275,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"72edd019-84b0-4a97-a8ed-e3893e9afecc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentiment(polarity=1.0, subjectivity=1.0)"]},"metadata":{},"execution_count":18}],"source":["TextBlob(\"Tendulkar is greatest batsman in Cricket\").sentiment # Sentiment of sentence"]},{"cell_type":"code","execution_count":null,"id":"23b4d380-ea10-45c7-a8fc-3fcc87a8277f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23b4d380-ea10-45c7-a8fc-3fcc87a8277f","executionInfo":{"status":"ok","timestamp":1763981492111,"user_tz":-330,"elapsed":43,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"b41094a2-9283-42f3-c128-6964661c94c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentiment(polarity=0.8, subjectivity=0.75)"]},"metadata":{},"execution_count":19}],"source":["TextBlob(\"Tendulkar is great batsman\").sentiment"]},{"cell_type":"code","execution_count":null,"id":"d73ddf42-1455-4935-839d-cc333b30432b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d73ddf42-1455-4935-839d-cc333b30432b","executionInfo":{"status":"ok","timestamp":1763981492125,"user_tz":-330,"elapsed":11,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"1eb61388-b09e-466a-bb9a-0e3c0d1fd516"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentiment(polarity=0.5, subjectivity=0.5)"]},"metadata":{},"execution_count":20}],"source":["TextBlob(\"Tendulkar is most reputed cricketer\").sentiment"]},{"cell_type":"code","execution_count":null,"id":"b68ff8fc-4f03-49c1-829c-7d779d7f6ff8","metadata":{"id":"b68ff8fc-4f03-49c1-829c-7d779d7f6ff8"},"outputs":[],"source":["def analyze_sentiment(text):\n","    analysis=TextBlob(text)\n","    if analysis.sentiment.polarity>0:\n","        return \"Positive\"\n","    elif analysis.sentiment.polarity==0:\n","        return \"Neutral\"\n","    else:\n","        return \"Negative\""]},{"cell_type":"code","execution_count":null,"id":"abfbd2b1-12a8-4a5e-8efe-7267cbcbc76e","metadata":{"id":"abfbd2b1-12a8-4a5e-8efe-7267cbcbc76e"},"outputs":[],"source":["import pandas as pd\n","climatesentences=pd.DataFrame(climatesentences,columns=['sentence'])"]},{"cell_type":"code","execution_count":null,"id":"112b98a4-643e-4923-bf95-d598c756556f","metadata":{"id":"112b98a4-643e-4923-bf95-d598c756556f"},"outputs":[],"source":["climatesentences['sentiment']=[str(analyze_sentiment(x)) for x in climatesentences['sentence']]"]},{"cell_type":"code","execution_count":null,"id":"aa79371f-3278-4908-96d0-9ee8386e0b16","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115},"id":"aa79371f-3278-4908-96d0-9ee8386e0b16","executionInfo":{"status":"ok","timestamp":1763981492187,"user_tz":-330,"elapsed":33,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"06011f29-083f-436e-b36c-b65f9cad540d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Series([], Name: count, dtype: int64)"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>sentiment</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":24}],"source":["climatesentences['sentiment'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"8b9c7fcc-3108-474e-8b58-883068f962dc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"8b9c7fcc-3108-474e-8b58-883068f962dc","executionInfo":{"status":"ok","timestamp":1763981492206,"user_tz":-330,"elapsed":15,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"b9d064e4-32b6-446d-948c-228253eb462f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [sentence, sentiment]\n","Index: []"],"text/html":["\n","  <div id=\"df-253fad9d-86bd-43ce-bc25-f9497266a7bf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-253fad9d-86bd-43ce-bc25-f9497266a7bf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-253fad9d-86bd-43ce-bc25-f9497266a7bf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-253fad9d-86bd-43ce-bc25-f9497266a7bf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"climatesentences","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":25}],"source":["climatesentences.head()"]},{"cell_type":"code","execution_count":null,"id":"9a1c53c9-737d-4bb0-8844-3f39ade3710b","metadata":{"id":"9a1c53c9-737d-4bb0-8844-3f39ade3710b"},"outputs":[],"source":["# NLP uses words or tokens as fundamental point of analysis\n","climatewords=word_tokenize(paragraphs_txt)"]},{"cell_type":"code","execution_count":null,"id":"cbfa955d-fb8a-4e57-8c12-06e4755e87de","metadata":{"id":"cbfa955d-fb8a-4e57-8c12-06e4755e87de"},"outputs":[],"source":["# isalnum() will select only words and digits. All special characters deleted\n","climatewords=[w for w in climatewords if w.isalnum()]"]},{"cell_type":"code","execution_count":null,"id":"60f9df14-8f8e-4c3a-80b7-26b0b548c3a3","metadata":{"id":"60f9df14-8f8e-4c3a-80b7-26b0b548c3a3"},"outputs":[],"source":["# Remove Stopwords. Stopwords are list of words like is, a, an, the, then, to, etc. that\n","# are not required for analysis\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":null,"id":"1f706d03-4cc5-4969-aa4f-0b489a4b92c5","metadata":{"id":"1f706d03-4cc5-4969-aa4f-0b489a4b92c5"},"outputs":[],"source":["english_stopwords=set(stopwords.words(\"english\"))"]},{"cell_type":"code","execution_count":null,"id":"58c55597-cfa4-4957-a6e8-a7bf229435ee","metadata":{"id":"58c55597-cfa4-4957-a6e8-a7bf229435ee"},"outputs":[],"source":["climatewords=[w for w in climatewords if not w in english_stopwords]"]},{"cell_type":"code","execution_count":null,"id":"10438ddb-6ccf-4d75-8514-7ceb58987a14","metadata":{"id":"10438ddb-6ccf-4d75-8514-7ceb58987a14"},"outputs":[],"source":["climatewords=[w for w in climatewords if len(w)>2] # Select words more than 2 characters"]},{"cell_type":"code","execution_count":null,"id":"eb88ba40-5c39-455c-ad42-0d3374a2ba8e","metadata":{"id":"eb88ba40-5c39-455c-ad42-0d3374a2ba8e"},"outputs":[],"source":["from nltk.probability import FreqDist"]},{"cell_type":"code","execution_count":null,"id":"d57b6030-3d1e-4fe8-82eb-a1dcc29bcf31","metadata":{"id":"d57b6030-3d1e-4fe8-82eb-a1dcc29bcf31"},"outputs":[],"source":["wordfreq=FreqDist(climatewords) # most common or most frequent word"]},{"cell_type":"code","execution_count":null,"id":"e480edb0-2374-4168-b25a-abd788efaed8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e480edb0-2374-4168-b25a-abd788efaed8","executionInfo":{"status":"ok","timestamp":1763981492319,"user_tz":-330,"elapsed":37,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"0185f247-d669-4ff5-d72c-18397071f7b4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":34}],"source":["wordfreq.most_common(20)"]},{"cell_type":"code","execution_count":null,"id":"57e8d829-0db0-43f6-bd95-d68e551572bd","metadata":{"id":"57e8d829-0db0-43f6-bd95-d68e551572bd"},"outputs":[],"source":["# Word Cloud is a vizual representation of most frequent words. large font size most frequent\n","# small font size less frequent.\n","\n","from wordcloud import WordCloud"]},{"cell_type":"code","execution_count":null,"id":"81c99f9e-eed3-4170-823f-5ecc9a8613c2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"81c99f9e-eed3-4170-823f-5ecc9a8613c2","executionInfo":{"status":"error","timestamp":1763981492391,"user_tz":-330,"elapsed":63,"user":{"displayName":"Deepthi P","userId":"12699651234158985563"}},"outputId":"c49de678-67f5-44ff-ca17-45ed5b01d01f"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"We need at least 1 word to plot a word cloud, got 0.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-834540609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m wordcloud=WordCloud(width=1000,height=500,stopwords=english_stopwords,\n\u001b[0;32m----> 2\u001b[0;31m                     colormap=\"plasma\",max_words=200).generate(str(climatewords))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \"\"\"\n\u001b[1;32m    623\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n\u001b[0m\u001b[1;32m    411\u001b[0m                              \"got %d.\" % len(frequencies))\n\u001b[1;32m    412\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."]}],"source":["wordcloud=WordCloud(width=1000,height=500,stopwords=english_stopwords,\n","                    colormap=\"plasma\",max_words=200).generate(str(climatewords))"]},{"cell_type":"code","execution_count":null,"id":"3356cbd0-de77-4dcc-91d5-e3c853ee6596","metadata":{"id":"3356cbd0-de77-4dcc-91d5-e3c853ee6596"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.imshow(wordcloud)"]},{"cell_type":"code","execution_count":null,"id":"e8aada43-fb58-457c-9423-c540c6e6f9fa","metadata":{"id":"e8aada43-fb58-457c-9423-c540c6e6f9fa"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}